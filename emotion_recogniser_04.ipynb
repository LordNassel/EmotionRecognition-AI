{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: emotion_recogniser_04.py\n",
    "Author: Gabor Levai\n",
    "Email: levaigabor.net@gmail.com\n",
    "Description: Emotion recognition with CNN\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "#matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#%% Data inspection\n",
    "\n",
    "train = pd.read_csv(\"training.csv\")\n",
    "test = pd.read_csv(\"publictest.csv\")\n",
    "train.head()\n",
    "\n",
    "print (\"The number of traning set samples: {}\".format(len(train)))\n",
    "print (\"The number of testing set samples: {}\".format(len(test)))\n",
    "#%%\n",
    "print (\"Training dataset emotion and its count\")\n",
    "train.emotion.value_counts()\n",
    "#%%\n",
    "print (\"Testing dataset emotion and its count\")\n",
    "test.emotion.value_counts()\n",
    "\n",
    "#%%#%%Data pre-processing\n",
    "\n",
    "#convert flatten data to 48*48 matrix\n",
    "def reshapeTo48and48(dataset):\n",
    "    #extract pixels value from original pandas dataframe\n",
    "    pixels_values = dataset.pixels.str.split(\" \").tolist()\n",
    "    #convert pixels of each image to 48*48 formats\n",
    "    images = []\n",
    "    for image in np.array(pixels_values, dtype=float):\n",
    "        images.append(image.reshape(48, 48))\n",
    "    return np.array(images, dtype=float)\n",
    "\n",
    "train_images = reshapeTo48and48(train)\n",
    "test_images = reshapeTo48and48(test)\n",
    "\n",
    "#reshape to [# of samples][width][height][pixels] for tensorflow-keras input format\n",
    "train_images = train_images.reshape(train_images.shape[0], 48, 48, 1).astype('float32')\n",
    "test_images = test_images.reshape(test_images.shape[0], 48, 48, 1).astype('float32')\n",
    "\n",
    "#check input format\n",
    "train_images.shape\n",
    "\n",
    "#normilize the data\n",
    "train_images = train_images/255\n",
    "test_images = test_images/255\n",
    "\n",
    "#One hot encode outputs: change target(emotion) values to input format with one-hot encode\n",
    "train_targets = np_utils.to_categorical(train.emotion.values)\n",
    "test_targets = np_utils.to_categorical(test.emotion.values)\n",
    "\n",
    "#set number of prediction classes\n",
    "num_classes = test_targets.shape[1]\n",
    "\n",
    "#%% Show emotion picture from data randomly\n",
    "\n",
    "def Plot_SomeEmotion_Sample_Randomly(emotion, dataset):\n",
    "    #select certain emotion sub dataset\n",
    "    EmotionSet = dataset[dataset.emotion == emotion]\n",
    "    #randomly select one sample\n",
    "    pixels_list = EmotionSet.sample(1).pixels.str.split(\" \").tolist()\n",
    "    #convert to 48*48 format\n",
    "    show_image = np.array(pixels_list, dtype=float).reshape(48,48)\n",
    "    #plot the image\n",
    "    plt.imshow(show_image, cmap='gray')\n",
    "    \n",
    "#%%\n",
    "#plot randomly disgust image\n",
    "Plot_SomeEmotion_Sample_Randomly(1, train)\n",
    "#%%\n",
    "#plot randomly happy image\n",
    "Plot_SomeEmotion_Sample_Randomly(3, train)\n",
    "\n",
    "#%% CNN MODEL\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, strides=1, \\\n",
    "            padding='same', activation='relu', \\\n",
    "            input_shape=input_shape))\n",
    "    # 48*48*64\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "    # 24*24*64\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, strides=1, \\\n",
    "            padding='same', activation='relu'))\n",
    "    # 24*24*128\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "    # 12*12*128\n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, strides=1, \\\n",
    "            padding='same', activation='relu'))\n",
    "    # 12*12*256\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
    "    # 7*7*256\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1792, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "#%% Training model\n",
    "\n",
    "#PARAMETERS#\n",
    "input_shape = (48, 48, 1)\n",
    "num_classes = 7\n",
    "MODEL_NAME = 'emotion_recogniser_04'\n",
    "\n",
    "#set information to save model and for early stopping\n",
    "filename = \"model_04.hdf5\"\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10)\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_acc', verbose=2, save_best_only=True, mode='auto')\n",
    "\n",
    "\n",
    "##complie\n",
    "model = build_model(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "    \n",
    "##begin to train and save training history\n",
    "history = model.fit(train_images, train_targets, validation_data=(test_images, test_targets), \n",
    "                    epochs=100, batch_size=160, callbacks=[early_stopping, checkpoint], verbose=2)\n",
    "\n",
    "#%% Plot\n",
    "\n",
    "# plot history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Accuracy-Iteration Graph')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iteration(epoch)')\n",
    "plt.legend(['train',  'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#%% Load saved trained model & show the final analysis\n",
    "\n",
    "#build a saved_model and load weights\n",
    "Saved_model = build_model(input_shape, num_classes)\n",
    "Saved_model.load_weights(\"model_04.hdf5\")\n",
    "Saved_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#get loss value and accuracy for testing set\n",
    "scores = Saved_model.evaluate(test_images, test_targets, verbose=0)\n",
    "\n",
    "#print accuracy\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "#%% Draw confusion matrix to evaluate the final model\n",
    "\n",
    "Saved_prediction = Saved_model.predict_classes(test_images, verbose=0)\n",
    "True_prediction = test.emotion.values\n",
    "\n",
    "cm = confusion_matrix(True_prediction, Saved_prediction)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, int(cm[i, j]*100)/100.0,\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "plot_confusion_matrix(cm, classes=class_names, normalize=False,\n",
    "                      title='Confusion Matrix for Test Dataset')\n",
    "plt.show()\n",
    "#%%\n",
    "\n",
    "def export_model(saver, model, input_node_names, output_node_name):\n",
    "    tf.train.write_graph(K.get_session().graph_def, 'out', \\\n",
    "        MODEL_NAME + '_graph.pbtxt')\n",
    "\n",
    "    saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')\n",
    "\n",
    "    freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \\\n",
    "        False, 'out/' + MODEL_NAME + '.chkp', output_node_name, \\\n",
    "        \"save/restore_all\", \"save/Const:0\", \\\n",
    "        'out/frozen_' + MODEL_NAME + '.pb', True, \"\")\n",
    "\n",
    "    input_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.Open('out/frozen_' + MODEL_NAME + '.pb', \"rb\") as f:\n",
    "        input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "            input_graph_def, input_node_names, [output_node_name],\n",
    "            tf.float32.as_datatype_enum)\n",
    "\n",
    "    with tf.gfile.FastGFile('out/opt_' + MODEL_NAME + '.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "    print(\"graph saved!\")\n",
    "#%%    \n",
    "    export_model(tf.train.Saver(), model, [\"conv2d_1_input\"], \"dense_2/Softmax\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
